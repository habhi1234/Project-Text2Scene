{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeM_Z9Gpoo6b"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "\n",
        "!pip install torch torchvision\n",
        "!pip install -U git+https://github.com/luca-medeiros/lang-segment-anything.git\n",
        "!pip install -U llamaapi langchain-experimental\n",
        "\n",
        "output.clear()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!npm install localtunnel\n",
        "\n",
        "!git clone https://github.com/omriav/blended-latent-diffusion.git\n",
        "!conda env create -f environment.yaml\n",
        "!pip install diffusers\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "sPBb0rF8yuP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import locale\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "os.makedirs(\"/content/outputs\")"
      ],
      "metadata": {
        "id": "5cW3K3NzTDWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP Frontend\n",
        "%%writefile nlp_frontend.py\n",
        "import locale\n",
        "import json\n",
        "from typing import List\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
        "\n",
        "from llamaapi import LlamaAPI\n",
        "from langchain_experimental.llms import ChatLlamaAPI\n",
        "\n",
        "\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "llama = LlamaAPI(\"LL-IKBw9svOF3WJ18BD2KtxKCcClwg0OxJWPLCdsNQpPPjyLaxb02L1CqK2K1Rc4i9X\")\n",
        "model = ChatLlamaAPI(client=llama)\n",
        "\n",
        "class ImageEdit(BaseModel):\n",
        "    mask: str = Field(description=\"The part of the input that signifies what object, entity or noun needs to removed from a particular image.\")\n",
        "    subject: str = Field(description=\"The part of the input that declares what object, entity or noun needs to be added to the image.\")\n",
        "\n",
        "from langchain.chains import create_tagging_chain\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"mask\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"TThe part of the input that signifies what object, entity or noun needs to removed from a particular image.\",\n",
        "        },\n",
        "        \"subject\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The part of the input that declares what object, entity or noun needs to be added to the image.\",\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "nlp_frontend = create_tagging_chain(schema, model)\n",
        "\n",
        "def prompt_split(prompt):\n",
        "  try:\n",
        "    x = nlp_frontend.run(prompt)\n",
        "    if type(x['mask']) != str:\n",
        "      return x['mask']['enum'], x['subject']['enum']\n",
        "    else:\n",
        "      return x['mask'], x['subject']\n",
        "  except Exception as e:\n",
        "    print(\"Error. Try again.\")"
      ],
      "metadata": {
        "id": "BTxvxa47eMt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14b327e-76c2-4a57-c799-7df50e74b4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing nlp_frontend.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9SVPJ86n6AA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c51bad-9b7a-408f-e983-6c90515c0116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing langsam.py\n"
          ]
        }
      ],
      "source": [
        "# LangSAM Model\n",
        "%%writefile langsam.py\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from lang_sam import LangSAM\n",
        "\n",
        "\n",
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "def save_mask(mask_np, filename):\n",
        "    mask_image = Image.fromarray((mask_np * 255).astype(np.uint8))\n",
        "    mask_image.save(filename)\n",
        "\n",
        "def display_image_with_masks(image, masks):\n",
        "    num_masks = len(masks)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_masks + 1, figsize=(15, 5))\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    for i, mask_np in enumerate(masks):\n",
        "        axes[i+1].imshow(mask_np, cmap='gray')\n",
        "        axes[i+1].set_title(f\"Mask {i+1}\")\n",
        "        axes[i+1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_image_with_boxes(image, boxes, logits):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(\"Image with Bounding Boxes\")\n",
        "    ax.axis('off')\n",
        "\n",
        "    for box, logit in zip(boxes, logits):\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "        confidence_score = round(logit.item(), 2)  # Convert logit to a scalar before rounding\n",
        "        box_width = x_max - x_min\n",
        "        box_height = y_max - y_min\n",
        "\n",
        "        # Draw bounding box\n",
        "        rect = plt.Rectangle((x_min, y_min), box_width, box_height, fill=False, edgecolor='red', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # Add confidence score as text\n",
        "        ax.text(x_min, y_min, f\"Confidence: {confidence_score}\", fontsize=8, color='red', verticalalignment='top')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def print_bounding_boxes(boxes):\n",
        "    print(\"Bounding Boxes:\")\n",
        "    for i, box in enumerate(boxes):\n",
        "        print(f\"Box {i+1}: {box}\")\n",
        "\n",
        "def print_detected_phrases(phrases):\n",
        "    print(\"\\nDetected Phrases:\")\n",
        "    for i, phrase in enumerate(phrases):\n",
        "        print(f\"Phrase {i+1}: {phrase}\")\n",
        "\n",
        "def print_logits(logits):\n",
        "    print(\"\\nConfidence:\")\n",
        "    for i, logit in enumerate(logits):\n",
        "        print(f\"Logit {i+1}: {logit}\")\n",
        "\n",
        "def langsam(image, text_prompt):\n",
        "    # Suppress warning messages\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    image_pil = Image.open(image).convert(\"RGB\")\n",
        "    image_pil.save(\"/content/image.jpeg\")\n",
        "\n",
        "    model = LangSAM()\n",
        "    masks, boxes, phrases, logits = model.predict(image_pil, text_prompt)\n",
        "\n",
        "    if len(masks) == 0:\n",
        "        print(f\"No objects of the '{text_prompt}' prompt detected in the image.\")\n",
        "    else:\n",
        "        # Convert masks to numpy arrays\n",
        "        masks_np = [mask.squeeze().cpu().numpy() for mask in masks]\n",
        "\n",
        "        # Display the original image and masks side by side\n",
        "        #display_image_with_masks(image_pil, masks_np)\n",
        "\n",
        "        # Display the image with bounding boxes and confidence scores\n",
        "        #display_image_with_boxes(image_pil, boxes, logits)\n",
        "\n",
        "        # Save the masks\n",
        "        for i, mask_np in enumerate(masks_np):\n",
        "            mask_path = f\"image_mask_{i+1}.png\"\n",
        "            save_mask(mask_np, mask_path)\n",
        "        im_mask = plt.imread(\"image_mask_1.png\")\n",
        "        # Print the bounding boxes, phrases, and logits\n",
        "        #print_bounding_boxes(boxes)\n",
        "        #print_detected_phrases(phrases)\n",
        "        #print_logits(logits)\n",
        "        return masks_np[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import PIL.Image\n",
        "import os\n",
        "from nlp_frontend import prompt_split\n",
        "from langsam import langsam\n",
        "\n",
        "st.markdown(\"<h1 style='text-align: center;'>Text2Scene</h1>\", unsafe_allow_html=True)\n",
        "\n",
        "# Row 1: Text Prompt\n",
        "text_prompt = st.text_input(\"Enter a description of the image you want:\")\n",
        "\n",
        "# Row 2: Image Selector\n",
        "image_file = st.file_uploader(\"Choose an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "if image_file is not None:\n",
        "    st.image(image_file, caption=\"Selected Image\")\n",
        "\n",
        "# Button - Bottom of screen\n",
        "if st.button(\"Generate Image\"):\n",
        "    # Replace this with your image generation logic\n",
        "    maskprompt, genprompt = prompt_split(text_prompt)\n",
        "    st.write('To mask  - ', maskprompt)\n",
        "    st.write('To fill  - ', genprompt)\n",
        "    output_mask = langsam(image_file, maskprompt)\n",
        "    st.image(\"/content/image_mask_1.png\", caption=\"Generated Mask\")\n",
        "    os.system(f'python /content/blended-latent-diffusion/scripts/text_editing_SD2.py --prompt \"{genprompt}\" --init_image \"/content/image.jpeg\" --mask \"/content/image_mask_1.png\"')\n",
        "    st.image(\"/content/outputs/res.jpg\", caption=\"Generated Image\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv-P9nMPI8j",
        "outputId": "2836b8a6-08dc-4000-ace4-34235979bf9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwrPkBJVVk2Z",
        "outputId": "de4b431e-95a8-4e0a-a11e-3413c6f4b3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.87.164.207\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.661s\n",
            "your url is: https://shaky-kids-rest.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wCfBcuz2pSoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}